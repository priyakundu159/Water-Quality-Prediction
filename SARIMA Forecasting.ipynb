{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv('/Users/priyakundu/Documents/NYU Capstone WaterVue Files/Sample_Dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the dataframe to get unique values from \"Analysis\" column as columns\n",
    "df_pivot = df.pivot_table(index=['Site #', 'Location', 'Sample Date'], columns='Analysis', values='Result').reset_index()\n",
    "\n",
    "# Group by sample date and location\n",
    "pivoted_df = df_pivot.groupby(['Sample Date', 'Location']).first().reset_index()\n",
    "\n",
    "# Print the new dataframe\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns using indexing\n",
    "pivoted_df.columns = [*pivoted_df.columns[:-2], 'Turbidity1', 'Turbidity2']\n",
    "\n",
    "# Merge the \"Turbidity1\" and \"Turbidity2\" columns into a single column named \"Turbidity1\"\n",
    "pivoted_df['Turbidity'] = pivoted_df['Turbidity1'].combine_first(pivoted_df['Turbidity2'])\n",
    "\n",
    "# Drop the \"old\" columns\n",
    "pivoted_df.drop(columns=['Turbidity1' , 'Turbidity2'], inplace=True)\n",
    "\n",
    "# Merge the \"Chlorophyll A\" and \"Chlorophyll a\" columns into a single column named \"Chlorophyll A\"\n",
    "pivoted_df['Chlorophyll A'] = pivoted_df['Chlorophyll A'].combine_first(pivoted_df['Chlorophyll a'])\n",
    "\n",
    "# Drop the \"Chlorophyll a\" column\n",
    "pivoted_df.drop(columns=['Chlorophyll a'], inplace=True)\n",
    "\n",
    "# Drop 'Sample Date' column\n",
    "pivoted_df.drop(['Copper', 'Site #'], axis=1, inplace=True)\n",
    "\n",
    "# Print the cleaned dataframe\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Sample Date' column to datetime\n",
    "pivoted_df['Sample Date'] = pd.to_datetime(pivoted_df['Sample Date'])\n",
    "\n",
    "# Set 'Sample Date' as index\n",
    "pivoted_df.set_index('Sample Date', inplace=True)\n",
    "\n",
    "# Group by 'Location' and resample yearly for each group\n",
    "resampled_df = pivoted_df.groupby('Location').resample('6M').mean().reset_index()\n",
    "\n",
    "# Output the resampled data\n",
    "resampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find null values in the DataFrame\n",
    "null_values = resampled_df.isnull()\n",
    "\n",
    "# Count null values in each column\n",
    "null_counts = null_values.sum()\n",
    "\n",
    "print(\"Null values in each column:\")\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of unique values in the column\n",
    "num_unique_values = resampled_df['Location'].nunique()\n",
    "\n",
    "# Count the occurrences of each value in the column\n",
    "value_counts = resampled_df['Location'].value_counts()\n",
    "\n",
    "print(\"Number of unique values:\", num_unique_values)\n",
    "print(\"Occurrences of each value:\")\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mode (most frequent value count)\n",
    "mode_value_count = value_counts.mode()[0]\n",
    "\n",
    "mode_value_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the rows with the mode value count\n",
    "filtered_df = resampled_df[resampled_df['Location'].map(resampled_df['Location'].value_counts()) == mode_value_count]\n",
    "\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = filtered_df.fillna(method=\"ffill\")\n",
    "\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Specify the path where you want to save the CSV file\n",
    "# # csv_file_path = 'Final_Dataframe_WaterQual.csv'\n",
    "\n",
    "# # Convert DataFrame to CSV\n",
    "# cleaned_df.to_csv('Ultimate_Dataframe_WaterQual.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = cleaned_df.sort_values(by='Sample Date', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "train_data = sorted_df.iloc[:-4*cleaned_df[\"Location\"].nunique()].sort_values(by=['Location', 'Sample Date'], ascending=True)  # Use all but the last 2 years for training\n",
    "test_data = sorted_df.iloc[-4*cleaned_df[\"Location\"].nunique():].sort_values(by=['Location', 'Sample Date'], ascending=True)   # Use the last 2 years for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chlorophyll A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 'Chlorophyll A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for location in train_data[\"Location\"].unique():\n",
    "    train_df = train_data[train_data[\"Location\"]==location]\n",
    "    test_df = test_data[test_data[\"Location\"]==location]\n",
    "\n",
    "    # Fit SARIMA model\n",
    "    order = (5, 1, 1)       # Example (p, d, q)\n",
    "    seasonal_order = (1, 2, 0, 2)  # Example (P, D, Q, s) - Changed seasonal order to avoid overlapping AR lags\n",
    "    model = SARIMAX(train_df[param], order=order, seasonal_order=seasonal_order)\n",
    "    result = model.fit()\n",
    "\n",
    "    # Forecast future values\n",
    "    forecast = result.get_forecast(steps=3)  # Forecasting next 3 years (6 biannual periods) into the future\n",
    "    forecast_index = pd.date_range(start=train_df[\"Sample Date\"].iloc[-1], periods=4, freq='6M')[1:]\n",
    "    forecast_values = forecast.predicted_mean\n",
    "\n",
    "    predictions.append(pd.DataFrame({\"Location\": [location]*3, \"Sample Date\": forecast_index,param: forecast_values}))\n",
    "pred_data = pd.concat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train and test data for plotting\n",
    "combined_data = pd.concat([train_data.assign(dataset='Train'), test_data.assign(dataset='Test'), pred_data.assign(dataset='Prediction')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"Sample Date\" to datetime\n",
    "combined_data[\"Sample Date\"] = pd.to_datetime(combined_data[\"Sample Date\"])\n",
    "\n",
    "# Create facet plot\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.set_style(\"whitegrid\")\n",
    "g = sns.FacetGrid(combined_data, col=\"Location\", hue=\"dataset\", col_wrap=5, height=3, aspect=1.5, sharey=False)\n",
    "\n",
    "# Iterate over each parameter and map them onto the facet grid for both train and test data\n",
    "line = g.map(sns.lineplot, \"Sample Date\", param, marker=\"o\")\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "for ax in g.axes.ravel():\n",
    "    ax.tick_params(labelrotation=45)\n",
    "\n",
    "plt.subplots_adjust(top=0.95)\n",
    "g.fig.suptitle('Parameters Over Time for Each Location')\n",
    "\n",
    "# Adjust legend\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes, mses, rmses = [], [], []\n",
    "for location in train_data[\"Location\"].unique():\n",
    "    test_df = test_data[test_data[\"Location\"]==location]\n",
    "    pred_df = pred_data[pred_data[\"Location\"]==location]\n",
    "    mae = mean_absolute_error(test_df[param], pred_df[param])\n",
    "    mse = mean_squared_error(test_df[param], pred_df[param])\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    maes.append(mae)\n",
    "    mses.append(mse)\n",
    "    rmses.append(rmse)\n",
    "accuracy = pd.DataFrame({\"Location\": train_data[\"Location\"].unique(),\n",
    "              \"MAE\": maes,\n",
    "              \"MSE\": mses,\n",
    "              \"RMSE\": rmses,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.sort_values(by=\"RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissolved Oxygen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 'Dissolved Oxygen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for location in train_data[\"Location\"].unique():\n",
    "    print(\"\\n\\n\")\n",
    "    print(location)\n",
    "    train_df = train_data[train_data[\"Location\"]==location]\n",
    "    test_df = test_data[test_data[\"Location\"]==location]\n",
    "\n",
    "    # Fit SARIMA model\n",
    "    order = (5, 1, 1)       # Example (p, d, q)\n",
    "    seasonal_order = (1, 1, 1, 2)  # Example (P, D, Q, s)\n",
    "    model = SARIMAX(train_df[param], order=order, seasonal_order=seasonal_order)\n",
    "    result = model.fit()\n",
    "\n",
    "    # Forecast future values\n",
    "    forecast = result.get_forecast(steps=3)  # Forecasting next 3 years (6 biannual periods) into the future\n",
    "    forecast_index = pd.date_range(start=train_df[\"Sample Date\"].iloc[-1], periods=4, freq='6M')[1:]\n",
    "    forecast_values = forecast.predicted_mean\n",
    "\n",
    "    predictions.append(pd.DataFrame({\"Location\": [location]*3, \"Sample Date\": forecast_index,param: forecast_values}))\n",
    "pred_data = pd.concat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train and test data for plotting\n",
    "combined_data = pd.concat([train_data.assign(dataset='Train'), test_data.assign(dataset='Test'), pred_data.assign(dataset='Prediction')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"Sample Date\" to datetime\n",
    "combined_data[\"Sample Date\"] = pd.to_datetime(combined_data[\"Sample Date\"])\n",
    "\n",
    "# Create facet plot\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.set_style(\"whitegrid\")\n",
    "g = sns.FacetGrid(combined_data, col=\"Location\", hue=\"dataset\", col_wrap=5, height=3, aspect=1.5, sharey=False)\n",
    "\n",
    "# Iterate over each parameter and map them onto the facet grid for both train and test data\n",
    "line = g.map(sns.lineplot, \"Sample Date\", param, marker=\"o\")\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "for ax in g.axes.ravel():\n",
    "    ax.tick_params(labelrotation=45)\n",
    "\n",
    "plt.subplots_adjust(top=0.95)\n",
    "g.fig.suptitle('Parameters Over Time for Each Location')\n",
    "\n",
    "# Adjust legend\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes, mses, rmses = [], [], []\n",
    "for location in train_data[\"Location\"].unique():\n",
    "    test_df = test_data[test_data[\"Location\"]==location]\n",
    "    pred_df = pred_data[pred_data[\"Location\"]==location]\n",
    "    mae = mean_absolute_error(test_df[param], pred_df[param])\n",
    "    mse = mean_squared_error(test_df[param], pred_df[param])\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    maes.append(mae)\n",
    "    mses.append(mse)\n",
    "    rmses.append(rmse)\n",
    "accuracy = pd.DataFrame({\"Location\": train_data[\"Location\"].unique(),\n",
    "              \"MAE\": maes,\n",
    "              \"MSE\": mses,\n",
    "              \"RMSE\": rmses,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.sort_values(by=\"RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 'Salinity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for location in train_data[\"Location\"].unique():\n",
    "    train_df = train_data[train_data[\"Location\"]==location]\n",
    "    test_df = test_data[test_data[\"Location\"]==location]\n",
    "\n",
    "    # Fit SARIMA model\n",
    "    order = (5, 1, 1)       # Example (p, d, q)\n",
    "    seasonal_order = (1, 1, 1, 2)  # Example (P, D, Q, s)\n",
    "    model = SARIMAX(train_df[param], order=order, seasonal_order=seasonal_order)\n",
    "    result = model.fit()\n",
    "\n",
    "    # Forecast future values\n",
    "    forecast = result.get_forecast(steps=3)  # Forecasting next 3 years (6 biannual periods) into the future\n",
    "    forecast_index = pd.date_range(start=train_df[\"Sample Date\"].iloc[-1], periods=4, freq='6M')[1:]\n",
    "    forecast_values = forecast.predicted_mean\n",
    "\n",
    "    predictions.append(pd.DataFrame({\"Location\": [location]*3, \"Sample Date\": forecast_index,param: forecast_values}))\n",
    "pred_data = pd.concat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train and test data for plotting\n",
    "combined_data = pd.concat([train_data.assign(dataset='Train'), test_data.assign(dataset='Test'), pred_data.assign(dataset='Prediction')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"Sample Date\" to datetime\n",
    "combined_data[\"Sample Date\"] = pd.to_datetime(combined_data[\"Sample Date\"])\n",
    "\n",
    "# Create facet plot\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.set_style(\"whitegrid\")\n",
    "g = sns.FacetGrid(combined_data, col=\"Location\", hue=\"dataset\", col_wrap=5, height=3, aspect=1.5, sharey=False)\n",
    "\n",
    "# Iterate over each parameter and map them onto the facet grid for both train and test data\n",
    "line = g.map(sns.lineplot, \"Sample Date\", param, marker=\"o\")\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "for ax in g.axes.ravel():\n",
    "    ax.tick_params(labelrotation=45)\n",
    "\n",
    "plt.subplots_adjust(top=0.95)\n",
    "g.fig.suptitle('Parameters Over Time for Each Location')\n",
    "\n",
    "# Adjust legend\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes, mses, rmses = [], [], []\n",
    "for location in train_data[\"Location\"].unique():\n",
    "    test_df = test_data[test_data[\"Location\"]==location]\n",
    "    pred_df = pred_data[pred_data[\"Location\"]==location]\n",
    "    mae = mean_absolute_error(test_df[param], pred_df[param])\n",
    "    mse = mean_squared_error(test_df[param], pred_df[param])\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    maes.append(mae)\n",
    "    mses.append(mse)\n",
    "    rmses.append(rmse)\n",
    "accuracy = pd.DataFrame({\"Location\": train_data[\"Location\"].unique(),\n",
    "              \"MAE\": maes,\n",
    "              \"MSE\": mses,\n",
    "              \"RMSE\": rmses,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.sort_values(by=\"RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific Conductance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 'Specific Conductance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for location in train_data[\"Location\"].unique():\n",
    "    train_df = train_data[train_data[\"Location\"]==location]\n",
    "    test_df = test_data[test_data[\"Location\"]==location]\n",
    "\n",
    "    # Fit SARIMA model\n",
    "    order = (5, 1, 1)       # Example (p, d, q)\n",
    "    seasonal_order = (1, 1, 1, 2)  # Example (P, D, Q, s)\n",
    "    model = SARIMAX(train_df[param], order=order, seasonal_order=seasonal_order)\n",
    "    result = model.fit()\n",
    "\n",
    "    # Forecast future values\n",
    "    forecast = result.get_forecast(steps=3)  # Forecasting next 3 years (6 biannual periods) into the future\n",
    "    forecast_index = pd.date_range(start=train_df[\"Sample Date\"].iloc[-1], periods=4, freq='6M')[1:]\n",
    "    forecast_values = forecast.predicted_mean\n",
    "\n",
    "    predictions.append(pd.DataFrame({\"Location\": [location]*3, \"Sample Date\": forecast_index,param: forecast_values}))\n",
    "pred_data = pd.concat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train and test data for plotting\n",
    "combined_data = pd.concat([train_data.assign(dataset='Train'), test_data.assign(dataset='Test'), pred_data.assign(dataset='Prediction')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"Sample Date\" to datetime\n",
    "combined_data[\"Sample Date\"] = pd.to_datetime(combined_data[\"Sample Date\"])\n",
    "\n",
    "# Create facet plot\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.set_style(\"whitegrid\")\n",
    "g = sns.FacetGrid(combined_data, col=\"Location\", hue=\"dataset\", col_wrap=5, height=3, aspect=1.5, sharey=False)\n",
    "\n",
    "# Iterate over each parameter and map them onto the facet grid for both train and test data\n",
    "line = g.map(sns.lineplot, \"Sample Date\", param, marker=\"o\")\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "for ax in g.axes.ravel():\n",
    "    ax.tick_params(labelrotation=45)\n",
    "\n",
    "plt.subplots_adjust(top=0.95)\n",
    "g.fig.suptitle('Parameters Over Time for Each Location')\n",
    "\n",
    "# Adjust legend\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes, mses, rmses = [], [], []\n",
    "for location in train_data[\"Location\"].unique():\n",
    "    test_df = test_data[test_data[\"Location\"]==location]\n",
    "    pred_df = pred_data[pred_data[\"Location\"]==location]\n",
    "    mae = mean_absolute_error(test_df[param], pred_df[param])\n",
    "    mse = mean_squared_error(test_df[param], pred_df[param])\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    maes.append(mae)\n",
    "    mses.append(mse)\n",
    "    rmses.append(rmse)\n",
    "accuracy = pd.DataFrame({\"Location\": train_data[\"Location\"].unique(),\n",
    "              \"MAE\": maes,\n",
    "              \"MSE\": mses,\n",
    "              \"RMSE\": rmses,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.sort_values(by=\"RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Nitrogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 'Total Nitrogen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for location in train_data[\"Location\"].unique():\n",
    "    train_df = train_data[train_data[\"Location\"]==location]\n",
    "    test_df = test_data[test_data[\"Location\"]==location]\n",
    "\n",
    "    # Fit SARIMA model\n",
    "    order = (5, 1, 1)       # Example (p, d, q)\n",
    "    seasonal_order = (1, 1, 1, 2)  # Example (P, D, Q, s)\n",
    "    model = SARIMAX(train_df[param], order=order, seasonal_order=seasonal_order)\n",
    "    result = model.fit()\n",
    "\n",
    "    # Forecast future values\n",
    "    forecast = result.get_forecast(steps=3)  # Forecasting next 3 years (6 biannual periods) into the future\n",
    "    forecast_index = pd.date_range(start=train_df[\"Sample Date\"].iloc[-1], periods=4, freq='6M')[1:]\n",
    "    forecast_values = forecast.predicted_mean\n",
    "\n",
    "    predictions.append(pd.DataFrame({\"Location\": [location]*3, \"Sample Date\": forecast_index,param: forecast_values}))\n",
    "pred_data = pd.concat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train and test data for plotting\n",
    "combined_data = pd.concat([train_data.assign(dataset='Train'), test_data.assign(dataset='Test'), pred_data.assign(dataset='Prediction')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"Sample Date\" to datetime\n",
    "combined_data[\"Sample Date\"] = pd.to_datetime(combined_data[\"Sample Date\"])\n",
    "\n",
    "# Create facet plot\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.set_style(\"whitegrid\")\n",
    "g = sns.FacetGrid(combined_data, col=\"Location\", hue=\"dataset\", col_wrap=5, height=3, aspect=1.5, sharey=False)\n",
    "\n",
    "# Iterate over each parameter and map them onto the facet grid for both train and test data\n",
    "line = g.map(sns.lineplot, \"Sample Date\", param, marker=\"o\")\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "for ax in g.axes.ravel():\n",
    "    ax.tick_params(labelrotation=45)\n",
    "\n",
    "plt.subplots_adjust(top=0.95)\n",
    "g.fig.suptitle('Parameters Over Time for Each Location')\n",
    "\n",
    "# Adjust legend\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes, mses, rmses = [], [], []\n",
    "for location in train_data[\"Location\"].unique():\n",
    "    test_df = test_data[test_data[\"Location\"]==location]\n",
    "    pred_df = pred_data[pred_data[\"Location\"]==location]\n",
    "    mae = mean_absolute_error(test_df[param], pred_df[param])\n",
    "    mse = mean_squared_error(test_df[param], pred_df[param])\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    maes.append(mae)\n",
    "    mses.append(mse)\n",
    "    rmses.append(rmse)\n",
    "accuracy = pd.DataFrame({\"Location\": train_data[\"Location\"].unique(),\n",
    "              \"MAE\": maes,\n",
    "              \"MSE\": mses,\n",
    "              \"RMSE\": rmses,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.sort_values(by=\"RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Phosphorus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 'Total Phosphorus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for location in train_data[\"Location\"].unique():\n",
    "    train_df = train_data[train_data[\"Location\"]==location]\n",
    "    test_df = test_data[test_data[\"Location\"]==location]\n",
    "\n",
    "    # Fit SARIMA model\n",
    "    order = (5, 1, 1)       # Example (p, d, q)\n",
    "    seasonal_order = (1, 1, 1, 2)  # Example (P, D, Q, s)\n",
    "    model = SARIMAX(train_df[param], order=order, seasonal_order=seasonal_order)\n",
    "    result = model.fit()\n",
    "\n",
    "    # Forecast future values\n",
    "    forecast = result.get_forecast(steps=3)  # Forecasting next 3 years (6 biannual periods) into the future\n",
    "    forecast_index = pd.date_range(start=train_df[\"Sample Date\"].iloc[-1], periods=4, freq='6M')[1:]\n",
    "    forecast_values = forecast.predicted_mean\n",
    "\n",
    "    predictions.append(pd.DataFrame({\"Location\": [location]*3, \"Sample Date\": forecast_index,param: forecast_values}))\n",
    "pred_data = pd.concat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train and test data for plotting\n",
    "combined_data = pd.concat([train_data.assign(dataset='Train'), test_data.assign(dataset='Test'), pred_data.assign(dataset='Prediction')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"Sample Date\" to datetime\n",
    "combined_data[\"Sample Date\"] = pd.to_datetime(combined_data[\"Sample Date\"])\n",
    "\n",
    "# Create facet plot\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.set_style(\"whitegrid\")\n",
    "g = sns.FacetGrid(combined_data, col=\"Location\", hue=\"dataset\", col_wrap=5, height=3, aspect=1.5, sharey=False)\n",
    "\n",
    "# Iterate over each parameter and map them onto the facet grid for both train and test data\n",
    "line = g.map(sns.lineplot, \"Sample Date\", param, marker=\"o\")\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "for ax in g.axes.ravel():\n",
    "    ax.tick_params(labelrotation=45)\n",
    "\n",
    "plt.subplots_adjust(top=0.95)\n",
    "g.fig.suptitle('Parameters Over Time for Each Location')\n",
    "\n",
    "# Adjust legend\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes, mses, rmses = [], [], []\n",
    "for location in train_data[\"Location\"].unique():\n",
    "    test_df = test_data[test_data[\"Location\"]==location]\n",
    "    pred_df = pred_data[pred_data[\"Location\"]==location]\n",
    "    mae = mean_absolute_error(test_df[param], pred_df[param])\n",
    "    mse = mean_squared_error(test_df[param], pred_df[param])\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    maes.append(mae)\n",
    "    mses.append(mse)\n",
    "    rmses.append(rmse)\n",
    "accuracy = pd.DataFrame({\"Location\": train_data[\"Location\"].unique(),\n",
    "              \"MAE\": maes,\n",
    "              \"MSE\": mses,\n",
    "              \"RMSE\": rmses,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.sort_values(by=\"RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turbidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 'Turbidity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for location in train_data[\"Location\"].unique():\n",
    "    train_df = train_data[train_data[\"Location\"]==location]\n",
    "    test_df = test_data[test_data[\"Location\"]==location]\n",
    "\n",
    "    # Fit SARIMA model\n",
    "    order = (5, 1, 1)       # Example (p, d, q)\n",
    "    seasonal_order = (1, 1, 1, 2)  # Example (P, D, Q, s)\n",
    "    model = SARIMAX(train_df[param], order=order, seasonal_order=seasonal_order)\n",
    "    result = model.fit()\n",
    "\n",
    "    # Forecast future values\n",
    "    forecast = result.get_forecast(steps=3)  # Forecasting next 3 years (6 biannual periods) into the future\n",
    "    forecast_index = pd.date_range(start=train_df[\"Sample Date\"].iloc[-1], periods=4, freq='6M')[1:]\n",
    "    forecast_values = forecast.predicted_mean\n",
    "\n",
    "    predictions.append(pd.DataFrame({\"Location\": [location]*3, \"Sample Date\": forecast_index,param: forecast_values}))\n",
    "pred_data = pd.concat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train and test data for plotting\n",
    "combined_data = pd.concat([train_data.assign(dataset='Train'), test_data.assign(dataset='Test'), pred_data.assign(dataset='Prediction')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"Sample Date\" to datetime\n",
    "combined_data[\"Sample Date\"] = pd.to_datetime(combined_data[\"Sample Date\"])\n",
    "\n",
    "# Create facet plot\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.set_style(\"whitegrid\")\n",
    "g = sns.FacetGrid(combined_data, col=\"Location\", hue=\"dataset\", col_wrap=5, height=3, aspect=1.5, sharey=False)\n",
    "\n",
    "# Iterate over each parameter and map them onto the facet grid for both train and test data\n",
    "line = g.map(sns.lineplot, \"Sample Date\", param, marker=\"o\")\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "for ax in g.axes.ravel():\n",
    "    ax.tick_params(labelrotation=45)\n",
    "\n",
    "plt.subplots_adjust(top=0.95)\n",
    "g.fig.suptitle('Parameters Over Time for Each Location')\n",
    "\n",
    "# Adjust legend\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes, mses, rmses = [], [], []\n",
    "for location in train_data[\"Location\"].unique():\n",
    "    test_df = test_data[test_data[\"Location\"]==location]\n",
    "    pred_df = pred_data[pred_data[\"Location\"]==location]\n",
    "    mae = mean_absolute_error(test_df[param], pred_df[param])\n",
    "    mse = mean_squared_error(test_df[param], pred_df[param])\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    maes.append(mae)\n",
    "    mses.append(mse)\n",
    "    rmses.append(rmse)\n",
    "accuracy = pd.DataFrame({\"Location\": train_data[\"Location\"].unique(),\n",
    "              \"MAE\": maes,\n",
    "              \"MSE\": mses,\n",
    "              \"RMSE\": rmses,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.sort_values(by=\"RMSE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
